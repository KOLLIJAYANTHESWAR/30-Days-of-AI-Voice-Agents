ğŸ™ï¸ AI Voice Conversational Agent (FastAPI):
An advanced real-time AI-powered voice assistant that transcribes your speech, generates intelligent and context-aware responses using Google Gemini, and speaks back to you with natural-sounding voices using Murf AI. Built with FastAPI, it supports session-based conversations, multiple voice selections, and a modern, interactive UI.

âœ¨ Features:
--> Speech-to-Text â€“ Accurate transcription using AssemblyAI.
--> AI Response Generation â€“ Context-aware replies from Google Gemini.
--> Text-to-Speech â€“ Lifelike voice synthesis via Murf AI.
--> Session-based Conversation Memory â€“ Maintains dialogue history per user.
--> Modern UI â€“ Dark/Light theme toggle, animated aura orb, live waveform visualization.
--> Fast & Async â€“ Built on FastAPI with async calls for low latency.
--> Modular Design â€“ Easily replace APIs or extend features.

ğŸ— Architecture:
ğŸ¤ User Speech
      â†“
[Frontend UI]
      â†“ (audio file)
[FastAPI Backend]
      â†“
AssemblyAI (Speech-to-Text)
      â†“
Google Gemini (AI Chat Generation)
      â†“
Murf AI (Text-to-Speech)
      â†“ (audio URL)
[Frontend UI - Plays AI Voice Response]


ğŸ— Architecture Diagram:
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚        User Device        â”‚
           â”‚   (Browser Frontend UI)   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ Audio (file)
                       â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚        FastAPI Backend      â”‚
          â”‚   (app.py / main.py)        â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚           â”‚
                  â–¼           â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  AssemblyAI     â”‚  â”‚ Google Gemini   â”‚
       â”‚ (Speech-to-Text)â”‚  â”‚ (AI Response)   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
               â”‚                        â”‚
               â–¼                        â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Murf AI      â”‚
  â”‚ (Text-to-Speechâ”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ Audio URL
          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Browser Plays Response â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ğŸ›  Tech Stack:
Backend: FastAPI, Python 3.11+
Frontend: HTML, CSS, JavaScript
APIs: AssemblyAI, Google Gemini, Murf AI
Tools & Libraries:
httpx â€“ Async HTTP requests
pydantic & pydantic-settings â€“ Config validation
python-dotenv â€“ Environment variable management
logging â€“ Structured logging


ğŸ“¦ Installation:
1ï¸âƒ£ Clone the Repository:
git clone https://github.com/your-username/ai-voice-agent.git
cd ai-voice-agent

2ï¸âƒ£ Create & Activate Virtual Environment
python -m venv venv
source venv/bin/activate  # Mac/Linux
venv\Scripts\activate     # Windows

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Set Up Environment Variables
Create a .env file in the root directory:

MURF_API_KEY=your_murf_api_key
ASSEMBLYAI_API_KEY=your_assemblyai_api_key
GEMINI_API_KEY=your_gemini_api_key

5ï¸âƒ£ Run the Backend
uvicorn main:app --reload

Backend will be available at:
â¡ http://127.0.0.1:8000

ğŸ“¡ API Endpoints
GET /
Serves the frontend UI (static/index.html).
POST /agent/chat/{session_id}
Handles speech-to-text, AI generation, and text-to-speech.

Request:
Path Parameter: session_id â€“ unique ID for each conversation.

Form Data:
file â€“ Audio file (required)

voice_id â€“ Murf AI voice ID (optional, default "en-US-natalie")
Response (JSON):
{
  "audio_url": "https://murf.ai/output/xyz123.mp3",
  "user_text": "Hello there!",
  "ai_text": "Hi! How can I assist you today?"
}

ğŸ¯ Usage Flow:
User records voice â†’ Frontend sends to /agent/chat/{session_id}.
Backend transcribes via AssemblyAI.
Google Gemini generates AI response.
Murf AI turns text into audio.
Frontend plays AIâ€™s voice response.

ğŸ“Œ Example .env Configuration:
MURF_API_KEY=xxxxxxxxxxxxxxxxxxxx
ASSEMBLYAI_API_KEY=xxxxxxxxxxxxxxxxxxxx
GEMINI_API_KEY=xxxxxxxxxxxxxxxxxxxx

ğŸ”® Future Enhancements:
ğŸ§ Real-time streaming transcription & response
ğŸŒ Multi-language support
ğŸ—‚ Save conversation history to a database
ğŸ“± Mobile-friendly PWA version

ğŸ¤ Contributing:
Fork this repository
Create your feature branch (git checkout -b feature/my-feature)
Commit changes (git commit -m 'Add my feature')
Push to branch (git push origin feature/my-feature)
Create Pull Request

ğŸ“œ License:
MIT License â€“ free to use and modify.